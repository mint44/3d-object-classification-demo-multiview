{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-64b49bfb9771>, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-64b49bfb9771>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    render_path =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "# coding=utf-8\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "from render_26 import render_view\n",
    "\n",
    "# Keras\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Flask utils\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from gevent.pywsgi import WSGIServer\n",
    "\n",
    "# Define a flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Model saved with Keras model.save()\n",
    "MODEL_PATH = 'models/your_model.h5'\n",
    "\n",
    "# Load your trained model\n",
    "# model = load_model(MODEL_PATH)\n",
    "# model._make_predict_function()          # Necessary\n",
    "# print('Model loaded. Start serving...')\n",
    "\n",
    "# You can also use pretrained model from Keras\n",
    "# Check https://keras.io/applications/\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50(weights='imagenet')\n",
    "print('Model loaded. Check http://127.0.0.1:5000/')\n",
    "\n",
    "\n",
    "def model_predict(img_path, model):\n",
    "    print(img_path)\n",
    "    render_path = './render/'+img_path+'/'\n",
    "    render_view(img_path , render_path,0,25)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "    # Preprocessing the image\n",
    "    x = image.img_to_array(img)\n",
    "    # x = np.true_divide(x, 255)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Be careful how your trained model deals with the input\n",
    "    # otherwise, it won't make correct prediction!\n",
    "    x = preprocess_input(x, mode='caffe')\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    return preds\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    # Main page\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        # Get the file from post request\n",
    "        f = request.files['file']\n",
    "\n",
    "        # Save the file to ./uploads\n",
    "        basepath = os.path.dirname(__file__)\n",
    "        file_path = os.path.join(\n",
    "            basepath, 'uploads', secure_filename(f.filename))\n",
    "        f.save(file_path)\n",
    "\n",
    "        # Make prediction\n",
    "        preds = model_predict(file_path, model)\n",
    "\n",
    "        # Process your result for human\n",
    "        # pred_class = preds.argmax(axis=-1)            # Simple argmax\n",
    "        pred_class = decode_predictions(preds, top=1)   # ImageNet Decode\n",
    "        result = str(pred_class[0][0][1])               # Convert to string\n",
    "        return result\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # app.run(port=5002, debug=True)\n",
    "\n",
    "    # Serve the app with gevent\n",
    "    http_server = WSGIServer(('', 5000), app)\n",
    "    http_server.serve_forever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tqdm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b26a6b2e3aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named tqdm"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "modules=list(resnet.children())[:-1]\n",
    "resnet=nn.Sequential(*modules)\n",
    "for p in resnet.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "class ImageDataset(data.Dataset):\n",
    "  \"\"\"My Image dataset.\"\"\"\n",
    "  \n",
    "  def __init__(self, csv_file, root_dir, transform=None):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "          csv_file (string): Path to the csv file with annotations.\n",
    "          root_dir (string): Directory with all the images.\n",
    "          transform (callable, optional): Optional transform to be applied\n",
    "              on a sample.\n",
    "      \"\"\"\n",
    "      self.csv_frame = pd.read_csv(csv_file,header = None, delim_whitespace=True)\n",
    "      self.root_dir = root_dir\n",
    "      self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.csv_frame)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      img_name = os.path.join(self.root_dir,\n",
    "                              self.csv_frame.iloc[idx, 0])\n",
    "      sample = io.imread(img_name.strip())[:,:,:3] #keep RGB, remove A\n",
    "      target = self.csv_frame.iloc[idx, 1]\n",
    "\n",
    "\n",
    "      if self.transform:\n",
    "          sample = self.transform(sample)\n",
    "\n",
    "      return sample, target\n",
    "\n",
    "\n",
    "class ImageDatasetFromList(data.Dataset):\n",
    "  \"\"\"My Image dataset.\"\"\"\n",
    "  \n",
    "  def __init__(self, list_file, transform=None):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "          csv_file (string): Path to the csv file with annotations.\n",
    "          root_dir (string): Directory with all the images.\n",
    "          transform (callable, optional): Optional transform to be applied\n",
    "              on a sample.\n",
    "      \"\"\"\n",
    "      self.root_dir = root_dir\n",
    "      self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.csv_frame)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      img_name = os.path.join(self.root_dir,\n",
    "                              self.csv_frame.iloc[idx, 0])\n",
    "      sample = io.imread(img_name.strip())[:,:,:3] #keep RGB, remove A\n",
    "      target = self.csv_frame.iloc[idx, 1]\n",
    "\n",
    "\n",
    "      if self.transform:\n",
    "          sample = self.transform(sample)\n",
    "\n",
    "      return sample, target\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "transfomation = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            #transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "trainset = ImageDataset('/home/minhb/ModelNet40/data/ModelNet40/modelnet40_test_list_label_26.csv', '/home/minhb/ModelNet40/data/ModelNet40/render_modelnet40_26/', transfomation)\n",
    "\n",
    "trainset_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                             batch_size=17, shuffle=False,\n",
    "                                             num_workers=2)\n",
    "\n",
    "def extract(model, data_loader):\n",
    "    result_x = np.zeros( (len(trainset_loader.dataset) , 2048))\n",
    "    result_target = np.zeros( (len(trainset_loader.dataset),1 ))\n",
    "    t = 0\n",
    "    model.eval()\n",
    "    for batch_idx, (x, target) in enumerate(tqdm.tqdm(data_loader)):\n",
    "        x, target = Variable(x, volatile=True).cuda(), Variable(target, volatile=True)\n",
    "        #print 'batch: ', batch_idx, 'size', x.shape\n",
    "        out = model(x)\n",
    "        out = out.cpu().data.numpy()\n",
    "        out = np.squeeze(out)\n",
    "        result_x[t: t + out.shape[0] , :] = out\n",
    "        result_target[t:t+out.shape[0] , :] = target\n",
    "        t = t + out.shape[0] \n",
    "        #print out.shape\n",
    "        \n",
    "    return result_x, result_target\n",
    "\n",
    "resnet = resnet.cuda()\n",
    "\n",
    "len(trainset_loader.dataset)\n",
    "\n",
    "x,y = extract(resnet, trainset_loader)\n",
    "\n",
    "np.save('x_test',x)\n",
    "np.save('y_test',y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_feature import extract_feature_from_list_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob('./render/uploads/038_371.ply/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_feature_from_list_imgs(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fcfded8149bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                      std=[0.229, 0.224, 0.225])\n\u001b[1;32m      3\u001b[0m transfomation = transforms.Compose([\n\u001b[1;32m      4\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m#transforms.Resize((224,224)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "transfomation = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            #transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "dt_loader = torch.utils.data.DataLoader(dtset,\n",
    "                                             batch_size=4, shuffle=False,\n",
    "                                             num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from classify_model import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((26,2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp (1, 8, 9, 2048)\n",
      "(8, 9, 2048) (8,)\n",
      "WARNING:tensorflow:From classify_model.py:272: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "restoring model from ./models/shrec18/model_best_testset.ckpt-110352\n",
      "INFO:tensorflow:Restoring parameters from ./models/shrec18/model_best_testset.ckpt-110352\n",
      "restored model from ./models/shrec18/model_best_testset.ckpt-110352\n",
      "3.0700662322999666 0.0\n",
      "accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "t = predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.04641808, 0.04884047, 0.04993571, 0.05685576, 0.04637186,\n",
       "         0.04863773, 0.0477536 , 0.0530273 , 0.05318277, 0.04965439,\n",
       "         0.04853301, 0.05079661, 0.0494514 , 0.04658845, 0.05168972,\n",
       "         0.05196531, 0.0517889 , 0.04782242, 0.04696047, 0.05372604]]),\n",
       " array([3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RING = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_score = class_score.reshape(-1,N_RING,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_mean = np.mean(class_score,1)\n",
    "preds = np.argmax(arg_mean,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = 'chair\tlight\tpc\ttable\tcup\tstorage\tdesk\tbag\tdisplay\tbookshelf\tbin\tbook\toven\tbed\tbox\tpillow\tmachine\tprinter\tsofa\tkeyboard'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1.][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flask.get_template_attribute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
